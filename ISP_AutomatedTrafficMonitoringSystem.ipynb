{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad02588",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "Detecting and tracking moving cars using frame differencing and background subtraction techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f478b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2de03e",
   "metadata": {},
   "source": [
    "Test if the video loads up. Press escape to end video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6f7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the video file\n",
    "video_path1 = 'Traffic_Laramie_1.mp4'\n",
    "video_path2 = 'Traffic_Laramie_2.mp4'\n",
    "cap = cv2.VideoCapture(video_path1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7b729",
   "metadata": {},
   "source": [
    "Create a background subtractor for the frames in the video, to see any movements in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae9734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path1)\n",
    "\n",
    "# Object detection from camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(frame)\n",
    "    \n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0dce2",
   "metadata": {},
   "source": [
    "Highlight the movement detection from the masked video into the original video by drawing contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "213f8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path1)\n",
    "\n",
    "# Object detection from camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(frame)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(frame, [cnt], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6ff33",
   "metadata": {},
   "source": [
    "Draw contours only if the area of the contour area is not above 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7e042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path1)\n",
    "\n",
    "# Object detection from camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(frame)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        # Calculate area and remove small elements\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(frame, [cnt], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296df5b3",
   "metadata": {},
   "source": [
    "Get the width and height to draw the Region Of Interest(ROI) for the main street in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd744963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n",
      "height: 600 width: 1040\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path1)\n",
    "\n",
    "# Object detection from camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "    print(\"height:\",height, \"width:\", width)\n",
    "    \n",
    "    # Extract region of interest(ROI)\n",
    "    roi = frame[270:720, 0: 1039]\n",
    "    \n",
    "    # Draw the region of interest (main street) on the frame\n",
    "    cv2.rectangle(frame, (0, 270), (1039, 590), (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Main Street\", (0, 265), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(roi)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        # Calculate area and remove small elements\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(roi, [cnt], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243a5a7",
   "metadata": {},
   "source": [
    "Perform frame differencing by comparing the current grayscale frame (gray2) with the grayscale frame of the previous time step (gray1), to identify changes in the scene. Draw a bounding rectangle for every car but ignore those with width less than 100 and height less than 25 (assuming those entities are not vehicles). Applied gaussian blur to the mask to make the detection better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92417728",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path1)\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "height, width, _ = frame1.shape\n",
    "\n",
    "# Convert the first frame to grayscale\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Object detection from a stable camera\n",
    "object_detector = cv2.createBackgroundSubtractorMOG2(history=100)\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    height, width, _ = frame2.shape\n",
    "    \n",
    "    # Convert the current frame to grayscale\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract region of interest (ROI)\n",
    "    roi = frame2[270:720, 0: 1039]\n",
    "    \n",
    "    # Object Detection\n",
    "    mask = object_detector.apply(roi)\n",
    "    \n",
    "    # Apply Gaussian blur to the mask\n",
    "    blurred_mask = cv2.GaussianBlur(mask, (31, 31), 0)\n",
    "    \n",
    "    _, blurred_mask = cv2.threshold(blurred_mask, 50, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(blurred_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        # Calculate area and remove small elements\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            # Ignore bounding boxes with width or height less than a certain threshold\n",
    "            if w > 100 and h > 25:\n",
    "                cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "    \n",
    "    # Draw the region of interest (main street) on the frame\n",
    "    cv2.rectangle(frame2, (0, 270), (1039, 590), (0, 0, 255), 2)\n",
    "    cv2.putText(frame2, \"Main Street\", (0, 265), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame2)\n",
    "    \n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a57f46",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "Counting the number of cars that go from city's downtown to the city centre for a specific time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560b31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868bf96",
   "metadata": {},
   "source": [
    "The code below uses two counting lines (line_start_first to line_end_first and line_start_second to line_end_second) to ensure accurate and reliable car counting, where the first line marks entry into the monitored region, and the second line confirms exit, preventing double counting and allowing for flexible region definition.The code also employs center circles within each bounding box to facilitate car motion detection. These circles aid in accurately tracking the movement of cars as they traverse the monitored area, enhancing the precision of the counting mechanism. After running both videos, the total car count and cars per minute are calculated and displayed in a Pandas DataFrame. The DataFrame includes video names, total car count, and cars per minute for each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa75143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Video Name  Total Number of Cars  Cars Per Minute\n",
      "0  Traffic_Laramie_1.mp4                     6              2.0\n",
      "1  Traffic_Laramie_2.mp4                     4              3.0\n"
     ]
    }
   ],
   "source": [
    "# Definition to process the video and start the car counting using two lines\n",
    "def process_video(video_path, line_start_first, line_end_first, line_start_second, line_end_second):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    ret, frame1 = cap.read()\n",
    "    height, width, _ = frame1.shape\n",
    "\n",
    "    object_detector = cv2.createBackgroundSubtractorMOG2(history=100)\n",
    "\n",
    "    car_count = 0\n",
    "    crossed_line_first = False\n",
    "    crossed_line_second = False\n",
    "    crossed_line_time_first = 0\n",
    "    crossed_line_time_second = 0\n",
    "    detection_delay = 2\n",
    "\n",
    "    while True:\n",
    "        ret, frame2 = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        mask = object_detector.apply(frame2)\n",
    "        blurred_mask = cv2.GaussianBlur(mask, (31, 31), 0)\n",
    "\n",
    "        _, blurred_mask = cv2.threshold(blurred_mask, 50, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(blurred_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area > 500:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                if w > 100 and h > 25:\n",
    "                    cv2.rectangle(frame2, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\n",
    "                    center_x, center_y = x + w // 2, y + h // 2\n",
    "                    cv2.circle(frame2, (center_x, center_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "                    if line_end_first[1] < center_y < line_start_first[1] and line_start_first[0] < center_x < line_end_first[0]:\n",
    "                        current_time_first = time.time()\n",
    "                        if not crossed_line_first and (current_time_first - crossed_line_time_first) > detection_delay:\n",
    "                            crossed_line_first = True\n",
    "                            crossed_line_time_first = current_time_first\n",
    "                            crossed_line_second = False\n",
    "\n",
    "                    if line_end_second[1] < center_y < line_start_second[1] and line_start_second[0] < center_x < line_end_second[0]:\n",
    "                        current_time_second = time.time()\n",
    "                        if not crossed_line_second and crossed_line_first and (current_time_second - crossed_line_time_second) > detection_delay:\n",
    "                            car_count += 1\n",
    "                            crossed_line_second = True\n",
    "                            crossed_line_time_second = current_time_second\n",
    "                        else:\n",
    "                            crossed_line_second = False\n",
    "\n",
    "        cv2.line(frame2, line_start_first, line_end_first, (0, 0, 255), 2)\n",
    "        cv2.line(frame2, line_start_second, line_end_second, (255, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame2, f\"Car Count: {car_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Frame\", frame2)\n",
    "\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return car_count\n",
    "\n",
    "# Define line parameters for both videos\n",
    "line_start_first = (290, 430)\n",
    "line_end_first = (310, 360)\n",
    "\n",
    "line_start_second = (210, 420)\n",
    "line_end_second = (230, 350)\n",
    "\n",
    "# Process each video and get the car count\n",
    "car_count1 = process_video(video_path1, line_start_first, line_end_first, line_start_second, line_end_second)\n",
    "car_count2 = process_video(video_path2, line_start_first, line_end_first, line_start_second, line_end_second)\n",
    "\n",
    "# Calculate cars per minute depending on length of video\n",
    "video_duration_minutes_1 = 2.75\n",
    "video_duration_minutes_2 = 1.45\n",
    "\n",
    "cars_per_minute_1 = car_count1 / video_duration_minutes_1\n",
    "cars_per_minute_2 = car_count2 / video_duration_minutes_2\n",
    "\n",
    "# Create a Pandas DataFrame to store the results\n",
    "data = {\n",
    "    \"Video Name\": [video_path1, video_path2],\n",
    "    \"Total Number of Cars\": [car_count1, car_count2],\n",
    "    \"Cars Per Minute\": [round(cars_per_minute_1, 0), round(cars_per_minute_2, 0)] # round up to whole number\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0639c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
